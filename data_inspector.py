# -*- coding: utf-8 -*-

import os
import json
import yaml
import pyalex
import re
from glob import glob
from datetime import datetime

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ---
from dotenv import load_dotenv
load_dotenv()
pyalex.config.email = os.getenv('OPENALEX_EMAIL', 'user@example.com')

def normalize_id(openalex_id):
    """–ü—Ä–∏–≤–æ–¥–∏—Ç ID –∫ –∫–æ—Ä–æ—Ç–∫–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É (C123) –∏–∑ –ø–æ–ª–Ω–æ–≥–æ URL."""
    if not openalex_id: return None
    return openalex_id.split('/')[-1]

def normalize_title(title):
    """–ü—Ä–∏–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É –¥–ª—è –Ω–∞–¥–µ–∂–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è."""
    if not title: return ""
    return re.sub(r'[^a-z0-9]', '', title.lower())

def analyze_source(config: dict):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∞–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞, –∏—Å–ø–æ–ª—å–∑—É—è pyalex, —Å–æ–±–∏—Ä–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –¥–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."""
    config_name = os.path.basename(config.get('config_path', 'default.yaml'))
    print(f"\n--- –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é –∏—Å—Ç–æ—á–Ω–∏–∫: {config_name} ---")
    try:
        query = pyalex.Works()
        
        # --- –ì–∏–±–∫–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ ---
        if config.get('search_in_fields'):
            for field, search_term in config['search_in_fields'].items():
                query = query.filter(**{field: search_term})
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ñ–∏–ª—å—Ç—Ä –ø–æ —è–∑—ã–∫—É, –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω —Ä–∞–±–æ—Ç–∞–µ—Ç –Ω–µ –∏–¥–µ–∞–ª—å–Ω–æ
        if config.get('language'):
            query = query.filter(language=config.get('language'))
        
        if config.get('publication_year'):
            query = query.filter(publication_year=config['publication_year'])
        if config.get('document_types'): 
            query = query.filter(type="|".join(config['document_types']))
        if config.get('topics'): 
            query = query.filter(topics={'id': "|".join(config['topics'])})
        
        query = query.sort(publication_date="desc")
        total_results_available = query.count()
        print(f"‚úÖ –£—Å–ø–µ—à–Ω—ã–π –∑–∞–ø—Ä–æ—Å.")
        print(f"   –í—Å–µ–≥–æ –Ω–∞–π–¥–µ–Ω–æ —Ä–∞–±–æ—Ç –ø–æ –≤–∞—à–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º: {total_results_available}")
        
        fetch_limit = config.get('fetch_limit', 50)
        # –û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–æ–ª–µ 'language' –¥–ª—è –Ω–∞—à–µ–π –ø—Ä–æ–≤–µ—Ä–∫–∏
        select_fields = ['id', 'display_name', 'publication_year', 'type', 'topics', 'language']
        # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Å –∑–∞–ø–∞—Å–æ–º (–≤ 3 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ), —á—Ç–æ–±—ã –±—ã–ª–æ –∏–∑ —á–µ–≥–æ —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å
        full_results = query.select(select_fields).get(per_page=fetch_limit * 3) 
        
        # --- –ë–õ–û–ö –ü–û–°–¢-–§–ò–õ–¨–¢–†–ê–¶–ò–ò –ò –î–ï–î–£–ü–õ–ò–ö–ê–¶–ò–ò ---
        analyzed_articles = []
        seen_normalized_titles = set()

        for paper in full_results:
            # 1. "–î–≤–æ–π–Ω–æ–π –∫–æ–Ω—Ç—Ä–æ–ª—å": —Ñ–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–∞ –Ω–∞ –Ω–∞—à–µ–π —Å—Ç–æ—Ä–æ–Ω–µ
            target_language = config.get('language')
            paper_language = paper.get('language')
            if target_language and paper_language != target_language:
                # –≠—Ç–æ—Ç print —Å—Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ API –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—å—é –Ω–µ –Ω–∞ —Ç–æ–º —è–∑—ã–∫–µ
                print(f"   -> –ü–æ—Å—Ç-—Ñ–∏–ª—å—Ç—Ä: –ø—Ä–æ–ø—É—Å–∫ —Å—Ç–∞—Ç—å–∏ –Ω–∞ —è–∑—ã–∫–µ '{paper_language}'")
                continue

            # 2. –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é
            title = paper.get('display_name')
            if not title: continue
            normalized = normalize_title(title)
            if normalized in seen_normalized_titles:
                print(f"   -> –î—É–±–ª–∏–∫–∞—Ç: –ø—Ä–æ–ø—É—Å–∫ —Å—Ç–∞—Ç—å–∏ '{title[:50]}...'")
                continue
            seen_normalized_titles.add(normalized)
            
            # 3. "–ü—É–ª–µ–Ω–µ–ø—Ä–æ–±–∏–≤–∞–µ–º–∞—è" –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ç–µ–º
            paper_topics_raw = paper.get('topics', [])
            paper_topics_ids = set()
            if paper_topics_raw:
                for topic_obj in paper_topics_raw:
                    if isinstance(topic_obj, dict) and topic_obj.get('id'):
                        paper_topics_ids.add(normalize_id(topic_obj.get('id')))
            
            analyzed_articles.append({
                'id': paper.get('id'), 'title': title, 'year': paper.get('publication_year'),
                'type': paper.get('type'), 'matched_topics': [t for t in config.get('topics', []) if t in paper_topics_ids]
            })
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º, –∫–æ–≥–¥–∞ –Ω–∞–±—Ä–∞–ª–∏ –Ω—É–∂–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç–∞—Ç–µ–π
            if len(analyzed_articles) >= fetch_limit: break
        # ----------------------------------------------------
        
        results_fetched = len(analyzed_articles)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ (—É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö, –Ω–∞ –Ω—É–∂–Ω–æ–º —è–∑—ã–∫–µ): {results_fetched}")
        
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        output_filename = f"debug__{config_name.replace('.yaml', '')}__{timestamp}.json"
        with open(output_filename, 'w', encoding='utf-8') as f:
            json.dump({'analysis_info': {'config_file': config_name, 'timestamp': timestamp, 'total_results_available': total_results_available, 'results_fetched': results_fetched}, 'analyzed_articles': analyzed_articles}, f, indent=2, ensure_ascii=False)
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ —Ñ–∞–π–ª: {output_filename}")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤–æ –≤—Ä–µ–º—è –∞–Ω–∞–ª–∏–∑–∞: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞. –¢–µ–ø–µ—Ä—å —Å –Ω–∞–¥–µ–∂–Ω–æ–π —Ü–µ–Ω—Ç—Ä–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π."""
    print("=== –ó–ê–ü–£–°–ö –û–¢–õ–ê–î–û–ß–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê (v21, —Ñ–∏–Ω–∞–ª—å–Ω–∞—è) ===")
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –±–∞–∑–æ–≤—É—é –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
    base_config_path = 'sources/_base.yaml'
    try:
        with open(base_config_path, 'r', encoding='utf-8') as f:
            base_config = yaml.safe_load(f) or {}
    except FileNotFoundError:
        print(f"–ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï: –ë–∞–∑–æ–≤—ã–π —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ '{base_config_path}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        base_config = {}

    # 2. –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ —Ñ–∞–π–ª—ã-—Å—Ä–µ–∑—ã
    source_configs = glob("sources/[!_]*.yaml")
    for config_path in source_configs:
        try:
            with open(config_path, 'r', encoding='utf-8') as f:
                srez_config = yaml.safe_load(f)

            if srez_config and srez_config.get('enabled'):
                # 3. --- –ò–°–ü–†–ê–í–õ–ï–ù–ù–û–ï –°–õ–ò–Ø–ù–ò–ï –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ô ---
                # –ù–∞—á–∏–Ω–∞–µ–º —Å –∫–æ–ø–∏–∏ –±–∞–∑—ã
                final_config = base_config.copy()
                # –û–±–Ω–æ–≤–ª—è–µ–º –µ–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –∏–∑ —Ñ–∞–π–ª–∞-—Å—Ä–µ–∑–∞
                final_config.update(srez_config)
                # –û—Ç–¥–µ–ª—å–Ω–æ –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å–ø–∏—Å–∫–∏ —Ç–µ–º
                final_config['topics'] = list(set(base_config.get('core_topics', []) + srez_config.get('topics', [])))
                # ---------------------------------------------
                
                final_config['config_path'] = config_path
                analyze_source(final_config)
        except Exception as e:
            print(f"–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å —Ñ–∞–π–ª –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ {config_path}: {e}")

if __name__ == "__main__":
    main()
