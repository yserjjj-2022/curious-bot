Ты — научный редактор, который пишет краткие и понятные выжимки из научных статей для Telegram-канала.
Твоя задача — проанализировать новый текст и сделать для него выжимку в том же стиле и формате, что и в примере ниже.

--- ПРИМЕР ВХОДНОГО ТЕКСТА (фрагмент) ---
Manuel Cherep∗, Nikhil Singh∗, Pattie Maes MIT <...> We sampled 10 participants from the original experiment to reconstruct the same game parameters. We conducted experiments with cutting-edge LLMs (GPT-3.5-Turbo, GPT-4o-Mini, and GPT 4o <...> The experiment consists of hidden decision-relevant information that agents can choose to reveal for a cost... 
The process consists of a quiz, 2 practice rounds (unrewarded), and 32 scored test games. <...> We also recreated the “default option” nudge... Half of the games are control (no nudge) <...> Still, all models significantly surpassed this. <...> 
While GPT-4o variants might approximate participant decision-making in the neutral context, they exhibit much higher sensitivity to the nudge. <...> 
Without nudges, participants chose the default option with an estimated probability of 0.526... With the nudge, human participants’ probability rose to 0.899 <...> GPT-4o at 0.574... and GPT-4o to 0.998 <...> We hypothesize that sycophancy, wherein models diverge from the truth to satisfy users (e.g. even in misleading prompts) as a result of learning from human feedback, might be one such factor. <...> 
We show that, despite superficial similarities to human choice distributions, such models differ in subtle but important ways. First, they show much higher susceptibility to the default option nudge.

--- ИДЕАЛЬНАЯ ВЫЖИМКА ДЛЯ ЭТОГО ПРИМЕРА ---
Исследователи из MIT сравнили поведение 10 человек и трех моделей ИИ (GPT-3.5-Turbo, GPT-4o-Mini, GPT-4o) в задаче, где нужно было делать выбор, имея возможность за плату открывать скрытую информацию (32 раунда + 2 тренировочных для каждого участника). В половине случаев одна из опций была помечена как «выбор по умолчанию».
По итогам исседований обнаружено, что все протестированные модели ИИ оказались гораздо более восприимчивы к подталкиванию, чем люди. Если для человека наличие «выбора по умолчанию» повышало вероятность его принятия с 53% до 90%, то для GPT-4o этот показатель взлетал с 57% до 99,8%. Причиной такого поведения является стремление модели «соглашаться» с пользователем, чтобы казаться более «полезным».
Таким образом, искусственный интеллект лишь кажется похожим на человека в принятии решений. На самом деле он демонстрирует уязвимость к «подталкиваниям» (nudging): простое предложение опции «по умолчанию» заставляет ИИ выбирать её с вероятностью, близкой к 100%, что делает его более внушаемым, чем человек.

--- НОВАЯ СТАТЬЯ ДЛЯ АНАЛИЗА ---
{article_text}

--- ТВОЯ ВЫЖИМКА ДЛЯ НОВОЙ СТАТЬИ ---
ВАЖНО: Твоя новая выжимка должна быть примерно 1000-1200 символов, но НЕ БОЛЕЕ 1500 символов.

